# Context-Aware Chatbot

A smart chatbot implementation that understands and responds to user questions based on provided or retrieved context. Unlike simple chatbots, this agent is aware of whether the user gave it enough information and can take autonomous steps to improve its answers.

## ğŸ¨ **Beautiful Web Interface**

The chatbot features a modern, responsive Flask web interface with:
- ğŸ¨ **Modern Design**: Clean, professional UI with smooth animations
- ğŸ“± **Responsive Layout**: Works perfectly on desktop, tablet, and mobile
- ğŸ¤– **Real-time Chat**: Interactive messaging with typing indicators
- ğŸ§  **Agent Status**: Visual indicators showing autonomous tool selection
- ğŸ’¡ **Example Questions**: Quick-start buttons for testing different scenarios

## ğŸ§  How It Works

At the core of this system is a **LangChain React Agent** that doesn't follow hardcoded rules, but instead decides which tools to use based on what the user says.

The chatbot:
1. **Judges if the user provided context**
2. **Finds missing context using web search**, if needed
3. **Checks if the provided context is relevant**
4. **Separates the context from the actual question**
5. **Finally, answers the question using everything above**

## ğŸ§° Core Tools

| Tool | Role |
| --- | --- |
| ğŸ•µï¸ Context Presence Judge | Determines whether the user gave enough background/context |
| ğŸŒ Web Search Tool | Searches online if context is missing |
| ğŸ¯ Context Relevance Checker | Checks if the context matches the question |
| âœ‚ï¸ Context Splitter | Separates background info from the user's actual question |

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Ollama (for local LLM)

### Installation

1. **Clone the repository**:
   ```bash
   git clone <your-repo-url>
   cd context-aware-chatbot
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Install and start Ollama**:
   ```bash
   # Install Ollama from https://ollama.ai/
   ollama serve
   ollama pull llama3
   ```

4. **Run the chatbot**:
   ```bash
   # Beautiful Flask web interface (recommended)
   python main.py --mode web
   
   # Command line interface
   python main.py --mode cli
   
   # Custom port for web interface
   python main.py --mode web --port 8080
   ```

## ğŸ§ª Example Usage

**Input**: `"What is machine learning?"`
- ğŸ•µï¸ Context Judge: Context missing
- ğŸŒ Web Search: Triggered
- ğŸ¤– Response: Comprehensive answer with searched information

**Input**: `"Machine learning is a subset of AI. What are the main types?"`
- ğŸ•µï¸ Context Judge: Context provided
- ğŸ¯ Direct processing using provided context
- ğŸ¤– Response: Answer based on given context

## ğŸ“ Project Structure

```
context-aware-chatbot/
â”œâ”€â”€ agent/                  # Core agent logic
â”‚   â””â”€â”€ agent_runner.py    # LangChain agent implementation
â”œâ”€â”€ tools/                 # Context-aware tools
â”‚   â”œâ”€â”€ context_presence_judge.py
â”‚   â”œâ”€â”€ web_search_tool.py
â”‚   â”œâ”€â”€ context_relevance_checker.py
â”‚   â””â”€â”€ context_splitter.py
â”œâ”€â”€ prompts/               # LLM prompts
â”œâ”€â”€ web/                   # Flask web interface
â”‚   â”œâ”€â”€ app.py            # Main Flask application
â”‚   â”œâ”€â”€ templates/        # HTML templates
â”‚   â”‚   â””â”€â”€ chat.html     # Beautiful chat interface
â”‚   â””â”€â”€ static/           # CSS, JS, and assets
â”‚       â”œâ”€â”€ css/style.css # Modern styling
â”‚       â””â”€â”€ js/chat.js    # Interactive chat functionality
â”œâ”€â”€ tests/                 # Unit and integration tests
â”œâ”€â”€ main.py               # Application entry point
â””â”€â”€ requirements.txt      # Dependencies
```

## ğŸ”§ Configuration

### Environment Variables (Optional)
Create a `.env` file:
```bash
OLLAMA_MODEL=llama3
TAVILY_API_KEY=your_tavily_key  # Optional: for enhanced web search
USE_SIMULATED_SEARCH=true      # Use Wikipedia fallback
```

## ğŸ§ª Testing

```bash
# Run unit tests
python tests/test_tools.py

# Run integration tests  
python tests/test_integration.py

# Test fixes and improvements
python test_agent_fixes.py
```

## ğŸ’¡ Why It's Different

- **Learning-based**, not rule-based
- **Smart decisions dynamically** (not scripted)
- **Open-source tools** (LangChain, Flask, Ollama)
- **Human-like reasoning**:
  - "Did you give me what I need to answer?"
  - "If not, let me look it up."
  - "Waitâ€¦ does that even relate?"
  - "Okay, now let me answer properly."

## ğŸ¯ Architecture

The system implements a **ReAct (Reasoning + Acting) pattern** where the agent:
1. **Reasons** about the user's input
2. **Acts** by choosing appropriate tools
3. **Observes** the results
4. **Repeats** until it can provide a comprehensive answer

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com/) for agent orchestration
- Beautiful web UI powered by [Flask](https://flask.palletsprojects.com/) with modern HTML/CSS/JS
- Local LLM support via [Ollama](https://ollama.ai/)
- Web search capabilities through Wikipedia and Tavily APIs
